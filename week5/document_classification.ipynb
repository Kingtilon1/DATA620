{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "In this section, I load the Spambase dataset from a CSV file using the `csv` module. This dataset contains various features extracted from emails to classify them as spam or non-spam. Each row represents an email, and each column represents a specific feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0.64', '0.64', '0', '0.32', '0', '0', '0', '0', '0', '0', '0.64', '0', '0', '0', '0.32', '0', '1.29', '1.93', '0', '0.96', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0.778', '0', '0', '3.756', '61', '278', '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('spambase.data', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "I convert the raw data into numerical format. Each row in the dataset represents an email, with features extracted from the email text. The features include word frequencies, character frequencies, and the lengths of capital letter sequences. Features are converted to floats and labels to integers. The dataset is then combined into a list of tuples where each tuple contains a dictionary of feature-value pairs and the corresponding label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First feature set: [0.0, 0.64, 0.64, 0.0, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64, 0.0, 0.0, 0.0, 0.32, 0.0, 1.29, 1.93, 0.0, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.778, 0.0, 0.0, 3.756, 61.0, 278.0]\n",
      "First label: 1\n"
     ]
    }
   ],
   "source": [
    "features = [list(map(float, row[:-1])) for row in data]\n",
    "labels = [int(row[-1]) for row in data]\n",
    "dataset = [(features[i], labels[i]) for i in range(len(features))]\n",
    "\n",
    "print(\"First feature set:\", features[0])\n",
    "print(\"First label:\", labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting\n",
    "The dataset is split into three parts: training set (70%), devtest set (15%), and test set (15%). This split ensures I have separate data for training, validating, and testing my model, allowing me to evaluate the model's performance on unseen data and make necessary adjustments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3220\n",
      "Devtest set size: 690\n",
      "Test set size: 691\n"
     ]
    }
   ],
   "source": [
    "split1 = int(0.7 * len(dataset))  # 70% for training\n",
    "split2 = int(0.85 * len(dataset)) # 15% for devtest, 15% for final test\n",
    "\n",
    "# split the data\n",
    "train_data = dataset[:split1]\n",
    "devtest_data = dataset[split1:split2]\n",
    "test_data = dataset[split2:]\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Devtest set size: {len(devtest_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function\n",
    "The `preprocess_data` function converts the raw data into a format suitable for NLTK. It creates a list of tuples where each tuple contains a dictionary of features and a label. This format is required by NLTK for training and evaluating classifiers. The function ensures that features are correctly mapped to their respective values and labels are appropriately assigned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row in data: ([0.0, 0.64, 0.64, 0.0, 0.32, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.64, 0.0, 0.0, 0.0, 0.32, 0.0, 1.29, 1.93, 0.0, 0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.778, 0.0, 0.0, 3.756, 61.0, 278.0], 1)\n",
      "First row in data: ([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.97, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.97, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.491, 0.163, 0.0, 0.0, 0.0, 4.312, 33.0, 138.0], 0)\n",
      "First row in data: ([0.0, 0.0, 0.3, 0.0, 0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.91, 0.0, 0.3, 0.0, 0.0, 0.0, 2.44, 0.61, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 1.52, 0.0, 0.0, 0.0, 0.0, 0.61, 1.22, 0.0, 0.0, 0.0, 0.0, 0.301, 0.043, 0.043, 0.0, 0.086, 0.0, 2.161, 19.0, 227.0], 0)\n",
      "First processed training sample: ({0: 0.0, 1: 0.64, 2: 0.64, 3: 0.0, 4: 0.32, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.64, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.32, 16: 0.0, 17: 1.29, 18: 1.93, 19: 0.0, 20: 0.96, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.778, 52: 0.0, 53: 0.0, 54: 3.756, 55: 61.0, 56: 278.0}, 1)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Function to convert raw data to feature-value pairs and labels\n",
    "def preprocess_data(data):\n",
    "    print(\"First row in data:\", data[0])\n",
    "    features = [list(map(float, row[0])) if isinstance(row[0], list) else list(map(float, row[:-1])) for row in data]\n",
    "    labels = [int(row[1]) if isinstance(row[0], list) else int(row[-1]) for row in data]\n",
    "    return [(dict(enumerate(features[i])), labels[i]) for i in range(len(features))]\n",
    "\n",
    "\n",
    "# Preprocess the training, devtest, and test sets\n",
    "train_set = preprocess_data(train_data)\n",
    "devtest_set = preprocess_data(devtest_data)\n",
    "test_set = preprocess_data(test_data)\n",
    "\n",
    "print(\"First processed training sample:\", train_set[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Naive Bayes Classifier\n",
    "I train a Naive Bayes classifier using the preprocessed training set. The Naive Bayes algorithm is suitable for spam classification because it handles large feature spaces well and is efficient in terms of computation. This classifier will learn to distinguish between spam and non-spam emails based on the features provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Devtest Set\n",
    "The trained classifier is evaluated on the devtest set to measure its accuracy. This helps me understand how well the model performs on unseen data and identify areas for improvement. I also display the most informative features that have the highest impact on distinguishing between spam and non-spam emails.\n",
    "\n",
    "The classifier achieved a devtest accuracy of 95.07%, indicating strong performance on new data. The most informative features are those that the model found most useful in making its predictions. For example, feature 56 (`capital_run_length_total`) with values like 9.0, 5.0, 4.0, and 6.0, strongly indicates non-spam. High values of this feature are much more likely to be found in non-spam emails, as shown by the high ratios (e.g., 23.7:1). Similarly, feature 23 (`char_freq_$`) with a value of 0.08 is a strong indicator of spam, with a ratio of 13.9:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devtest Accuracy: 0.9507246376811594\n",
      "Most Informative Features\n",
      "                      56 = 9.0                 0 : 1      =     23.7 : 1.0\n",
      "                      56 = 5.0                 0 : 1      =     21.6 : 1.0\n",
      "                      56 = 4.0                 0 : 1      =     16.7 : 1.0\n",
      "                      56 = 6.0                 0 : 1      =     15.1 : 1.0\n",
      "                      23 = 0.08                1 : 0      =     13.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.util import accuracy\n",
    "\n",
    "devtest_accuracy = accuracy(classifier, devtest_set)\n",
    "print(f'Devtest Accuracy: {devtest_accuracy}')\n",
    "\n",
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Test Set\n",
    "Finally, I evaluate the classifier on the test set to measure its overall performance and ensure it generalizes well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8437047756874095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier on the test set\n",
    "test_accuracy = accuracy(classifier, test_set)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sps620env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
